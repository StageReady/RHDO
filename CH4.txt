CH4

oc delete deployment -l app=my-app

oc process -f mysql-template.yaml -o yaml

oc process -f mysql-template.yaml --parameters

oc new-app --template mysql-persistent

Webpage:

From the Developer perspective, navigate to the +Add menu and click All Services in the Developer Catalog section to open the catalog. Then, enter the application name in the filter to search for a template for your application.

Topology menu and clicking Start building application or clicking the book icon.

oc create deployment my-app --image example.com/my-image:dev

oc set env deployment/my-app TEAM=red

oc run example-pod --image=registry.access.redhat.com/ubi8/httpd-24 --env GREETING='Hello from the awesome container' --port 8080

oc run example-pod --image=registry.access.redhat.com/ubi8/httpd-24 --env GREETING='Hello from the awesome container' --port 8080 --dry-run=client -o yaml

oc create -f my-app-deployment.yaml

oc new-app --file=./example/my-app.yaml

oc new-app --template mysql-persistent --param MYSQL_USER=operator --param MYSQL_PASSWORD=myP@55 --param MYSQL_DATABASE=mydata --param DATABASE_SERVICE_NAME=db

oc new-app --image example.com/my-app:dev

oc new-app https://github.com/apache/httpd.git#2.4.56

oc describe template mysql-ephemeral -n openshift

--------------------------------------------------------------------------------------------------------------

lab start deploy-newapp

oc login -u developer -p developer https://api.ocp4.example.com:6443

oc new-project deploy-newapp

oc get all

oc get serviceaccounts

oc get secrets

oc describe template mysql-persistent -n openshift

oc new-app -l team=red --template mysql-persistent -p MYSQL_USER=developer -p MYSQL_PASSWORD=developer

oc get pods

oc new-app --name db-image -l team=blue --image registry.ocp4.example.com:8443/rhel9/mysql-80:1 -e MYSQL_USER=developer -e MYSQL_PASSWORD=developer -e MYSQL_ROOT_PASSWORD=redhat

oc get pods -L team

oc get pods -l deploymentconfig=mysql -o jsonpath='{.items[0].spec.containers[0].readinessProbe}' | jq

oc get pods -l deployment=db-image -o jsonpath='{.items[0].spec.containers[0].readinessProbe}' | jq

oc get pods -l deploymentconfig=mysql -o jsonpath='{.items[0].spec.containers[0].resources.limits}' | jq

oc get pods -l deployment=db-image -o jsonpath='{.items[0].spec.containers[0].resources}' | jq

oc get secrets

oc get services

oc get services -l team=red

oc get pods -l team=red

oc delete all -l team=red

oc delete secret,pvc -l team=red

oc get secret,svc,pvc,dc -l team=red

oc get is,deployment,svc

lab finish deploy-newapp

--------------------------------------------------------------------------------------------------------------

oc create job date-job --image registry.access.redhat.com/ubi8/ubi -- /bin/bash -c "date"

oc create cronjob date-cronjob --image registry.access.redhat.com/ubi8/ubi --schedule "*/1 * * * *" -- date

oc create deployment my-deployment --image registry.access.redhat.com/ubi8/ubi --replicas 3

You can also create a deployment from the web console by clicking the Deployments tab in the Workloads menu.
Click Create Deployment and customize the form or the YAML manifest.

oc delete pod -l environment=testing

--------------------------------------------------------------------------------------------------------------

lab start deploy-workloads

oc login -u developer -p developer https://api.ocp4.example.com:6443

oc new-project deploy-workloads

oc create deployment my-db --image registry.ocp4.example.com:8443/rhel9/mysql-80:1

oc get deployments

oc get pods

oc logs deploy/my-db

oc set env deployment/my-db MYSQL_USER=developer MYSQL_PASSWORD=developer MYSQL_DATABASE=sampledb

oc get deployments

oc get pods -o wide

oc run -it db-test --restart=Never --image registry.ocp4.example.com:8443/rhel9/mysql-80:1 -- mysql sampledb -h 10.8.0.91 -u developer --password=developer -e "select 1;"

oc delete pod -l app=my-db

oc get pod -l app=my-db

oc create job date-loop --image registry.ocp4.example.com:8443/ubi9/ubi -- /bin/bash -c "for i in {1..30}; do date; done"

oc get job date-loop -o yaml

oc get jobs

oc logs job/date-loop

oc delete pod -l job-name=date-loop

oc get pod -l job-name=date-loop

oc get job -l job-name=date-loop

lab finish deploy-workloads

--------------------------------------------------------------------------------------------------------------

Kubernetes Pod and Service Networks

The Software-defined Network

DO CHECK THE SITE ABOUT INTRO TO K8S NET https://rha.ole.redhat.com/rha/app/courses/do180-4.14/pages/ch04s05/afc13612-c35a-47ee-be67-d71e1f05fb37

Example:

oc expose deployment/<deployment-name> [--selector <selector>][--port <port>][--target-port <target port>][--protocol <protocol>][--name <name>]

The oc expose command can use the --selector option to specify the label selectors to use. When the command is used without the --selector option, the command applies a selector to match the replication controller or replica set.

The --port option of the oc expose command specifies the port that the service listens on. This port is available only to pods within the cluster. If a port value is not provided, then the port is copied from the deployment configuration.

The --target-port option of the oc expose command specifies the name or number of the container port that the service uses to communicate with the pods.

The --protocol option determines the network protocol for the service. TCP is used by default.

The --name option of the oc expose command can explicitly name the service. If not specified, the service uses the same name that is provided for the deployment.

oc get service db-pod -o wide

oc get endpoints

oc describe deployment db-pod

oc get deployment/<deployment_name> -o yaml

cat /etc/resolv.conf

oc get -n openshift-network-operator deployment/network-operator

oc describe network.config/cluster

--------------------------------------------------------------------------------------------------------------

oc login -u developer -p developer https://api.ocp4.example.com:6443

oc project deploy-services

oc create deployment db-pod --port 3306 --image registry.ocp4.example.com:8443/rhel8/mysql-80

oc set env deployment/db-pod MYSQL_USER=user1 MYSQL_PASSWORD=mypa55w0rd MYSQL_DATABASE=items

oc get pods

oc get deployment

oc expose deployment/db-pod

oc get service db-pod -o wide

PODNAME=$(oc get pods -o jsonpath='{.items[0].metadata.name}')

oc get pod $PODNAME --show-labels

oc get endpoints

oc get pods -o wide

oc delete deployment.apps/db-pod

oc get service

oc get endpoints

oc create deployment db-pod --port 3306 --image registry.ocp4.example.com:8443/rhel8/mysql-80

oc set env deployment/db-pod MYSQL_USER=user1 MYSQL_PASSWORD=mypa55w0rd MYSQL_DATABASE=items

oc get pods --selector app=db-pod -o wide

oc get endpoints

oc run shell -it --image registry.ocp4.example.com:8443/openshift4/network-tools-rhel8

cat /etc/resolv.conf

nc -z db-pod.deploy-services 3306 && echo "Connection success to db-pod.deploy-services:3306" || echo "Connection failed"

exit

oc delete pod shell

oc new-project deploy-services-2

oc run shell -it --rm --image registry.ocp4.example.com:8443/openshift4/network-tools-rhel8 --restart Never -- nc -z db-pod.deploy-services.svc.cluster.local 3306 && echo "Connection success to db-pod.deploy-services.svc.cluster.local:3306" || echo "Connection failed"

oc project deploy-services

oc create job mysql-init --image registry.ocp4.example.com:8443/redhattraining/do180-dbinit:v1 -- /bin/bash -c "mysql -uuser1 -pmypa55w0rd --protocol tcp -h db-pod -P3306 items </tmp/db-init.sql"

DROP TABLE IF EXISTS `Item`;
CREATE TABLE `Item` (`id` BIGINT not null auto_increment primary key, `description` VARCHAR(100), `done` BIT);
INSERT INTO `Item` (`id`,`description`,`done`) VALUES (1,'Pick up newspaper', 0);
INSERT INTO `Item` (`id`,`description`,`done`) VALUES (2,'Buy groceries', 1);

oc get job

oc get pods

oc delete job mysql-init

oc get pods

oc run query-db -it --rm --image registry.ocp4.example.com:8443/redhattraining/do180-dbinit:v1 --restart Never -- mysql -uuser1 -pmypa55w0rd --protocol tcp -h db-pod -P3306 items -e 'select * from Item;'

oc get pods -o wide

POD_IP=$(oc get pod -l app=db-pod -o jsonpath='{.items[0].status.podIP}')

oc run shell --env POD_IP=$POD_IP -it --rm --image registry.ocp4.example.com:8443/openshift4/network-tools-rhel8 --restart Never -- nc -z $POD_IP 3306 && echo "Connection success to $POD_IP:3306" || echo "Connection failed"

lab finish deploy-services

--------------------------------------------------------------------------------------------------------------

Service Types

ClusterIP
Default. The ClusterIP type exposes the service on a cluster-internal IP address. The service is reachable only from within the cluster.

The ClusterIP service type is used for pod-to-pod routing within the RHOCP cluster, and enables pods to communicate with and to access each other. 
IP addresses for the ClusterIP services are assigned from a dedicated service network that is accessible only from inside the cluster. 

Load balancer
A load balancer instructs Kubernetes to interact with the cloud provider that the cluster is running in. The load balancer then provides an externally accessible IP address to the application.
The applications that use this service type become accessible from networks outside the cluster. Additional security configuration is required to prevent unintended access.

NodePort
Kubernetes exposes a service on a port on the node IP address. The port is exposed on all cluster nodes, and each node redirects traffic to the endpoints (pods) of the service.
A NodePort service requires allowing direct network connections to a cluster node, which is a security risk.

ExternalName
This service tells Kubernetes that the DNS name in the externalName field is the location of the resource that backs the service. When a DNS request is made against the Kubernetes DNS server, it returns the externalName in a Canonical Name (CNAME) record, and directs the client to look up the returned name to get the IP address.

oc expose service api-frontend --hostname api.apps.acme.com

oc delete route myapp-route

WEB:

Networking → Routes menu. Click Create Route and customize the name, the hostname, the path, and the service to route to by using the form view or the YAML manifest.

oc create ingress ingr-sakila --rule="ingr-sakila.apps.ocp4.example.com/*=sakila-service:8080"

oc delete ingress example-ingress

oc annotate ingress ingr-example ingress.kubernetes.io/affinity=cookie

oc annotate route route-example router.openshift.io/cookie_name=myapp

ROUTE_NAME=$(oc get route <route_name> -o jsonpath='{.spec.host}')

curl $ROUTE_NAME -k -c /tmp/cookie_jar

curl $ROUTE_NAME -k -b /tmp/cookie_jar

oc scale --replicas 5 deployment/scale

--------------------------------------------------------------------------------------------------------------

lab start deploy-routes

oc login -u developer -p developer https://api.ocp4.example.com:6443

oc project web-applications

oc create deployment satir-app --image registry.ocp4.example.com:8443/redhattraining/do180-httpd-app:v1

oc get pods

oc status

oc create deployment sakila-app --image registry.ocp4.example.com:8443/redhattraining/do180-httpd-app:v1

oc get pods

oc status

oc expose deployment satir-app --name satir-svc --port 8080 --target-port 8080

oc expose deployment sakila-app --name sakila-svc --port 8080 --target-port 8080

oc get services

oc get endpoints

oc get pods -o wide

oc expose service satir-svc --name satir

oc get routes

Field			Value
Host			ingr-sakila.apps.ocp4.example.com
Service name	sakila-svc
Port number		8080

oc create ingress ingr-sakila --rule "ingr-sakila.apps.ocp4.example.com/*=sakila-svc:8080"

oc get ingress

oc get routes

curl ingr-sakila.apps.ocp4.example.com

curl satir-web-applications.apps.ocp4.example.com

oc scale deployment sakila-app --replicas 2

oc get pods

oc get pods -o wide

oc get endpoints

oc annotate ingress ingr-sakila ingress.kubernetes.io/affinity=cookie

for i in {1..3}; do curl ingr-sakila.apps.ocp4.example.com ; done

curl ingr-sakila.apps.ocp4.example.com -c /tmp/cookie_jar

cat /tmp/cookie_jar

for i in {1..3}; do curl ingr-sakila.apps.ocp4.example.com -b /tmp/cookie_jar; done

for i in {1..3}; do curl ingr-sakila.apps.ocp4.example.com ; done

oc annotate route satir router.openshift.io/cookie_name="hello"

for i in {1..3}; do curl satir-web-applications.apps.ocp4.example.com; done

curl satir-web-applications.apps.ocp4.example.com -c /tmp/cookie_jar

cat /tmp/cookie_jar

for i in {1..3}; do curl satir-web-applications.apps.ocp4.example.com -b /tmp/cookie_jar; done

for i in {1..3}; do curl satir-web-applications.apps.ocp4.example.com; done

lab finish deploy-routes

--------------------------------------------------------------------------------------------------------------

https://rha.ole.redhat.com/rha/app/courses/do180-4.14/pages/ch04s09/afc13612-c35a-47ee-be67-d71e1f05fb37

--------------------------------------------------------------------------------------------------------------

Create a MySQL database deployment named mysql-app by using the registry.ocp4.example.com:8443/redhattraining/mysql-app:v1 image, and identify the root cause of the failure.:

oc create deployment mysql-app --image registry.ocp4.example.com:8443/redhattraining/mysql-app:v1

oc logs mysql-app-75dfd58f99-5xfqc

Configure the environment variables for the mysql-app deployment by using the following information:

oc set env deployment/mysql-app MYSQL_USER=redhat MYSQL_PASSWORD=redhat123 MYSQL_DATABASE=world_x

oc exec -it mysql-app-57c44f646-5qt2k -- /bin/bash -c "mysql -uredhat -predhat123 </tmp/world_x.sql"

oc rsh mysql-app-57c44f646-5qt2k

mysql -uredhat -predhat123 world_x

Create a service for the mysql-app deployment by using the following information:

oc expose deployment mysql-app --name mysql-service --port 3306 --target-port 3306

Create a web application deployment named php-app by using the registry.ocp4.example.com:8443/redhattraining/php-webapp:v1 image.:

oc create deployment php-app --image registry.ocp4.example.com:8443/redhattraining/php-webapp:v1

Create a service for the php-app deployment by using the following information:

oc expose deployment php-app --name php-svc --port 8080 --target-port 8080

oc expose service/php-svc --name phpapp

oc get routes

Test the connectivity between the web application and the MySQL database. In a web browser, navigate to the phpapp-database-applications.apps.ocp4.example.com route, and verify that the application retrieves data from the MySQL database.:

Navigate to the phpapp-database-applications.apps.ocp4.example.com route in the web browser.